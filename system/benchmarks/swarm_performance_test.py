#!/usr/bin/env python3
"""
âš”ï¸ Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø±Ø¨ Ø§Ù„Ø´Ø§Ù…Ù„ âš”ï¸
ÙŠØ®ØªØ¨Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…Ø¹ Ø£Ø¹Ø¯Ø§Ø¯ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„ÙˆØ­Ø¯Ø§Øª
"""

import time
import multiprocessing
import threading
import asyncio
import psutil
import numpy as np
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import json
from datetime import datetime

class SwarmPerformanceTester:
    def __init__(self):
        self.cpu_count = psutil.cpu_count()
        self.memory_gb = psutil.virtual_memory().total / (1024**3)
        self.results = {}
        
    def cpu_intensive_task(self, n):
        """Ù…Ù‡Ù…Ø© ÙƒØ«ÙŠÙØ© Ù„Ù€ CPU"""
        result = 0
        for i in range(n):
            result += sum([j**2 for j in range(1000)])
        return result
    
    def memory_intensive_task(self, size_mb):
        """Ù…Ù‡Ù…Ø© ÙƒØ«ÙŠÙØ© Ù„Ù„Ø°Ø§ÙƒØ±Ø©"""
        data = np.random.rand(size_mb * 1024 * 128)  # 128 = 1MB/8KB
        return data.mean()
    
    def io_intensive_task(self, iterations):
        """Ù…Ù‡Ù…Ø© ÙƒØ«ÙŠÙØ© Ù„Ù€ I/O"""
        temp_file = f"/mnt/ramdisk/tmp/test_{threading.current_thread().ident}.tmp"
        for i in range(iterations):
            with open(temp_file, 'w') as f:
                f.write("x" * 10000)
            with open(temp_file, 'r') as f:
                _ = f.read()
        return iterations
    
    async def async_network_simulation(self, requests):
        """Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ù‡Ø§Ù… Ø´Ø¨ÙƒØ© ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø©"""
        async def make_request():
            await asyncio.sleep(0.001)  # Ù…Ø­Ø§ÙƒØ§Ø© Ø²Ù…Ù† Ø§Ù„Ø´Ø¨ÙƒØ©
            return "response"
        
        tasks = [make_request() for _ in range(requests)]
        results = await asyncio.gather(*tasks)
        return len(results)
    
    def test_threading_performance(self, num_threads, workload_per_thread):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Threading"""
        start_time = time.time()
        start_cpu = psutil.cpu_percent(interval=0.1)
        start_mem = psutil.virtual_memory().percent
        
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(self.cpu_intensive_task, workload_per_thread) 
                      for _ in range(num_threads)]
            results = [f.result() for f in futures]
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent(interval=0.1)
        end_mem = psutil.virtual_memory().percent
        
        return {
            "duration": end_time - start_time,
            "avg_cpu": (start_cpu + end_cpu) / 2,
            "avg_memory": (start_mem + end_mem) / 2,
            "throughput": num_threads / (end_time - start_time)
        }
    
    def test_multiprocessing_performance(self, num_processes, workload_per_process):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Multiprocessing"""
        start_time = time.time()
        start_cpu = psutil.cpu_percent(interval=0.1)
        start_mem = psutil.virtual_memory().percent
        
        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            futures = [executor.submit(self.cpu_intensive_task, workload_per_process) 
                      for _ in range(num_processes)]
            results = [f.result() for f in futures]
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent(interval=0.1)
        end_mem = psutil.virtual_memory().percent
        
        return {
            "duration": end_time - start_time,
            "avg_cpu": (start_cpu + end_cpu) / 2,
            "avg_memory": (start_mem + end_mem) / 2,
            "throughput": num_processes / (end_time - start_time)
        }
    
    def test_async_performance(self, num_coroutines, requests_per_coroutine):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Async I/O"""
        async def run_test():
            start_time = time.time()
            tasks = [self.async_network_simulation(requests_per_coroutine) 
                    for _ in range(num_coroutines)]
            results = await asyncio.gather(*tasks)
            end_time = time.time()
            return {
                "duration": end_time - start_time,
                "total_requests": sum(results),
                "requests_per_second": sum(results) / (end_time - start_time)
            }
        
        return asyncio.run(run_test())
    
    def test_mixed_workload(self, num_units):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ø¨Ø¡ Ø¹Ù…Ù„ Ù…Ø®ØªÙ„Ø· (CPU + Memory + I/O)"""
        start_time = time.time()
        start_cpu = psutil.cpu_percent(interval=0.1)
        start_mem = psutil.virtual_memory().percent
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„: 40% CPU, 30% Memory, 30% I/O
        cpu_units = int(num_units * 0.4)
        mem_units = int(num_units * 0.3)
        io_units = int(num_units * 0.3)
        
        with ThreadPoolExecutor(max_workers=num_units) as executor:
            # CPU tasks
            cpu_futures = [executor.submit(self.cpu_intensive_task, 100) 
                          for _ in range(cpu_units)]
            # Memory tasks
            mem_futures = [executor.submit(self.memory_intensive_task, 10) 
                          for _ in range(mem_units)]
            # I/O tasks
            io_futures = [executor.submit(self.io_intensive_task, 50) 
                         for _ in range(io_units)]
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            all_futures = cpu_futures + mem_futures + io_futures
            results = [f.result() for f in all_futures]
        
        end_time = time.time()
        end_cpu = psutil.cpu_percent(interval=0.1)
        end_mem = psutil.virtual_memory().percent
        
        return {
            "duration": end_time - start_time,
            "avg_cpu": (start_cpu + end_cpu) / 2,
            "avg_memory": (start_mem + end_mem) / 2,
            "tasks_completed": len(results),
            "tasks_per_second": len(results) / (end_time - start_time)
        }
    
    def find_optimal_swarm_size(self):
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ø³Ø±Ø¨ Ø§Ù„Ø£Ù…Ø«Ù„"""
        test_sizes = [10, 25, 50, 75, 100, 125, 150, 200, 250, 300]
        optimal_results = {}
        
        print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø­Ø¬Ù… Ø§Ù„Ø³Ø±Ø¨ Ø§Ù„Ø£Ù…Ø«Ù„...")
        print(f"ğŸ“Š Ø§Ù„Ù†Ø¸Ø§Ù…: {self.cpu_count} CPUs, {self.memory_gb:.1f}GB RAM\n")
        
        for size in test_sizes:
            print(f"\nâš¡ Ø§Ø®ØªØ¨Ø§Ø± {size} ÙˆØ­Ø¯Ø©...")
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¹Ø¨Ø¡ Ø§Ù„Ù…Ø®ØªÙ„Ø·
            mixed_result = self.test_mixed_workload(size)
            
            # Ø§Ø®ØªØ¨Ø§Ø± Threading
            thread_result = self.test_threading_performance(size, 50)
            
            # Ø§Ø®ØªØ¨Ø§Ø± Async (Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¹Ù‚ÙˆÙ„Ø© ÙÙ‚Ø·)
            if size <= 200:
                async_result = self.test_async_performance(size, 100)
            else:
                async_result = {"requests_per_second": 0}
            
            efficiency = mixed_result["tasks_per_second"] / size
            
            optimal_results[size] = {
                "mixed_performance": mixed_result,
                "thread_performance": thread_result,
                "async_performance": async_result,
                "efficiency_score": efficiency,
                "cpu_saturation": mixed_result["avg_cpu"],
                "memory_usage": mixed_result["avg_memory"]
            }
            
            print(f"  âœ… Ø§Ù„ÙƒÙØ§Ø¡Ø©: {efficiency:.2f}")
            print(f"  ğŸ“ˆ CPU: {mixed_result['avg_cpu']:.1f}%")
            print(f"  ğŸ’¾ RAM: {mixed_result['avg_memory']:.1f}%")
        
        return optimal_results
    
    def generate_report(self, results):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        print("\n" + "="*60)
        print("âš”ï¸ ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø±Ø¨ Ø§Ù„Ø´Ø§Ù…Ù„ âš”ï¸")
        print("="*60)
        print(f"\nğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ–¥ï¸ Ø§Ù„Ù†Ø¸Ø§Ù…: {self.cpu_count} CPUs, {self.memory_gb:.1f}GB RAM")
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø£Ù…Ø«Ù„
        best_size = max(results.keys(), 
                       key=lambda x: results[x]["efficiency_score"] 
                       if results[x]["cpu_saturation"] < 90 else 0)
        
        print(f"\nğŸ† Ø­Ø¬Ù… Ø§Ù„Ø³Ø±Ø¨ Ø§Ù„Ø£Ù…Ø«Ù„: {best_size} ÙˆØ­Ø¯Ø©")
        print(f"   Ø§Ù„ÙƒÙØ§Ø¡Ø©: {results[best_size]['efficiency_score']:.3f}")
        print(f"   Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU: {results[best_size]['cpu_saturation']:.1f}%")
        print(f"   Ø§Ø³ØªØ®Ø¯Ø§Ù… RAM: {results[best_size]['memory_usage']:.1f}%")
        
        print("\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ ØªÙØµÙŠÙ„ÙŠØ©:")
        print("-" * 60)
        print(f"{'Ø§Ù„Ø­Ø¬Ù…':>6} | {'Ø§Ù„ÙƒÙØ§Ø¡Ø©':>8} | {'CPU%':>6} | {'RAM%':>6} | {'Ù…Ù‡Ø§Ù…/Ø«Ø§Ù†ÙŠØ©':>12}")
        print("-" * 60)
        
        for size in sorted(results.keys()):
            r = results[size]
            print(f"{size:6d} | {r['efficiency_score']:8.3f} | "
                  f"{r['cpu_saturation']:6.1f} | {r['memory_usage']:6.1f} | "
                  f"{r['mixed_performance']['tasks_per_second']:12.1f}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        with open('/workspace/system/benchmarks/swarm_results_latest.json', 'w') as f:
            json.dump(results, f, indent=2)
        
        return best_size

if __name__ == "__main__":
    print("âš”ï¸ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø±Ø¨ Ø§Ù„Ø´Ø§Ù…Ù„ âš”ï¸\n")
    
    tester = SwarmPerformanceTester()
    results = tester.find_optimal_swarm_size()
    optimal_size = tester.generate_report(results)
    
    print(f"\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±!")
    print(f"ğŸ“Œ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡ Ù„Ù„Ø³Ø±Ø¨: {optimal_size} ÙˆØ­Ø¯Ø©")